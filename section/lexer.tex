\section{Lexer}
The lexical analyzer has been written using flex.
It has the following responsabilities:
\begin{itemize}
\item Verify that the input stream is lexically correct;
\item Produce the token stream for the parser;
\item Set the \verb|bison/flex| variable \verb|yylloc| -- this
variable contains the information about the first column, last column,
first row and last row of the token read. More details on its usage in
bison can be read in the bison section \ref{sec:parser}.
\item Raise an error in case of a fract constant with denominator equal
to $0$ -- it is simply not considered as a valid lexeme.
\end{itemize}


\subsection{Lexemes}
We chose to define an identifier for each lexem, this enable us to change the
syntax of the F language without affecting its semantics and the other
components. Basically, the goal of this choice is to have something similar to
a C macro or a placeholder for the syntax symbols of the F language.
For example we have defined \verb|SUM| which is a placeholder for \verb|+|, so
if tomorrow we decide to use \verb|plus| to perform the arithmetic sum we can do
it transparently to the rest of the FAC code. This provides a great flexibility
for lexer symbols.

\subsection{Comments}
We have also implemented the regex which checks the comments. So it is possible
write comments in the source code of F programs. They will be simply discarded
during the phase of lexical analysis.

\subsection{Modularity}
The lexer can be generated on the fly. Indeed, each regex and each rule are
contained in a file which reflects respectively the regex and the rule purpose.
The regexs and the rules are automatically assembled by a python script.
The script reads two configuration files written in json. These files specifies
the order in which the regexs and the rules have to be written in the lexer.fl
file. Thus we can simply modify the configuration files to change the
the precedence of the lexer rules\footnote{precedence rules are applied only in
case of a tie}.